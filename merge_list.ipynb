{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\nimport glob\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndef say_hello():\n    d1=[['2011-01-01',1],\n        ['2011-01-02',2],\n        ['2011-01-04',4],\n        ]\n\n    d2=[['2011-01-01',10],\n        ['2011-01-03',30],\n        ['2011-01-04',40],\n        ]\n\n    d3=[\n        ['2011-01-02',200],\n        ['2011-01-05',500],\n        ['2011-01-03',300 ],\n        ]\n    \n    ## create pandas dataframe for each array\n    df1 = pd.DataFrame(d1)\n    df2 = pd.DataFrame(d2)\n    df3 = pd.DataFrame(d3)\n    \n    ##rename columns\n    df1.columns = ['date','v1']\n    df2.columns = ['date','v2']\n    df3.columns = ['date','v3']\n\n    \n    ##concat dataframes\n    df = pd.merge(df1,df2,how = 'outer')\n    df_3 = pd.merge(df,df3,how = 'outer')\n    print(df_3)","execution_count":120,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"say_hello()","execution_count":121,"outputs":[{"output_type":"stream","text":"         date   v1    v2     v3\n0  2011-01-01  1.0  10.0    NaN\n1  2011-01-02  2.0   NaN  200.0\n2  2011-01-04  4.0  40.0    NaN\n3  2011-01-03  NaN  30.0  300.0\n4  2011-01-05  NaN   NaN  500.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1=[['2011-01-01',1],\n        ['2011-01-02',2],\n        ['2011-01-04',4],\n        ]\n\nd2=[['2011-01-01',10],\n        ['2011-01-03',30],\n        ['2011-01-04',40],\n        ]\n\nd3=[\n        ['2011-01-02',200],\n        ['2011-01-05',500],\n        ['2011-01-03',300 ],\n        ]","execution_count":170,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\ndf = []\n## fully join d1,d2\n\n# init two index list\nd2Index = []\nd1Index = []\n\nfor list_d1 in d1:\n    ## get a d1 index list (datetime is the value inside list)\n    d1Index.append(list_d1[0])\n    \n    for list_d2 in d2:\n        ## get a d2 index list (datetime is the value inside list)\n        d2Index.append(list_d2[0])\n        \n        ## inner join d1,d2\n        if list_d1[0] == list_d2[0]:\n           df.append([list_d1[0],list_d1[1],list_d2[1]])\n    ## left join d1,d2\n    if list_d1[0] not in d2Index:\n        df.append([list_d1[0],list_d1[1],float('nan')])\n## right join d1,d2\nfor list_d2 in d2:\n    if list_d2[0] not in d1Index:\n        df.append([list_d2[0],float('nan'),list_d2[1]])","execution_count":171,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":172,"outputs":[{"output_type":"execute_result","execution_count":172,"data":{"text/plain":"[['2011-01-01', 1, 10],\n ['2011-01-02', 2, nan],\n ['2011-01-04', 4, 40],\n ['2011-01-03', nan, 30]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## fully join df,d3\n\n# init two index list\nd3Index = []\ndfIndex = []\n\nfor list_df in df:\n    ## get a df index list (datetime is the value inside list)\n    dfIndex.append(list_df[0])\n    \n    for list_d3 in d3:\n        ## get a d3 index list (datetime is the value inside list)\n        d3Index.append(list_d3[0])\n        \n        ## inner join df,d3\n        if list_d3[0] == list_df[0]:\n           result.append([list_d3[0],list_df[1],list_df[2],list_d3[1]])\n    ## left join df,d3\n    if list_df[0] not in d3Index:\n        result.append([list_df[0],list_df[1],list_df[2],float('nan')])\n## right join df,d3\nfor list_d3 in d3:\n    if list_d3[0] not in dfIndex:\n        result.append([list_d3[0],float('nan'),float('nan'),list_d3[1]])","execution_count":173,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":175,"outputs":[{"output_type":"execute_result","execution_count":175,"data":{"text/plain":"[['2011-01-01', 1, 10, nan],\n ['2011-01-02', 2, nan, 200],\n ['2011-01-04', 4, 40, nan],\n ['2011-01-03', nan, 30, 300],\n ['2011-01-05', nan, nan, 500]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}